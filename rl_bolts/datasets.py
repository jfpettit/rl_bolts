# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_datasets.ipynb (unless otherwise specified).

__all__ = ['PolicyGradientRLDataset', 'QPolicyGradientRLDataset']

# Cell
import torch
from torch.utils.data import Dataset, IterableDataset, DataLoader
import numpy as np

# Cell
class PolicyGradientRLDataset(Dataset):
    """
    A dataset for policy gradient RL algorithms.

    It returns a tuple of (state, action, advantage, reward, action_logp) at each index.

    Args:
    - data (NumPy array): Batch of interaction data to train on.
    """
    def __init__(
        self,
        data
    ):
        self.data = data

    def __len__(self):
        return len(self.data[2])

    def __getitem__(self, idx):
        state = self.data[0][idx]
        act = self.data[1][idx]
        adv = self.data[2][idx]
        rew = self.data[3][idx]
        logp = self.data[4][idx]

        return state, act, adv, rew, logp

# Cell
class QPolicyGradientRLDataset(Dataset):
    """
    A dataset for Q policy gradient algorithms.

    It returns a tuple of (state, next_state, action, reward, done).

    Args:
    - data (NumPy array): Numpy array of data to train on.
    """
    def __init__(
        self,
        data
    ):
        self.data = data

    def __len__(self):
        return len(self.data[3])

    def __getitem__(self, idx):
        obs = self.data[0][idx]
        obs2 = self.data[1][idx]
        act = self.data[2][idx]
        rew = self.data[3][idx]
        done = self.data[4][idx]
        return obs, obs2, act, rew, done